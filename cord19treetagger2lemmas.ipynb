{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cord19treetagger2lemmas.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9AEpp1a9fSvpOL6Xe6l9U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/cord19/blob/main/cord19treetagger2lemmas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJUPXvIuAWqU"
      },
      "source": [
        "# Python for linguistic reasearch\n",
        "## Project: extracting terminology\n",
        "\n",
        "1. Upload and examine a .vert text (output of the TreeTagger)\n",
        "- Orwell 1984 for En and De are available on https://heibox.uni-heidelberg.de/d/d65daff8341e467c82b1/\n",
        "- You can generate such file from your own texts with the TreeTagger\n",
        "2. We will create a pattern-based dictionary of terminological candidates, learning fundamentals of data preparation in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oYgbrJDARnE"
      },
      "source": [
        "import os, re, sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZVKodrwyfcv"
      },
      "source": [
        "# example for downloading files for different languages, e.g., German file in  from the https://heibox.uni-heidelberg.de/f/ea06aa47fe2d49959a62/\n",
        "# remove / insert comments to choose the language you want to work with\n",
        "\n",
        "# German\n",
        "# 1984\n",
        "# !wget https://heibox.uni-heidelberg.de/f/32856950701c444d8e21/?dl=1\n",
        "\n",
        "# Georgian\n",
        "# 1984\n",
        "!wget https://heibox.uni-heidelberg.de/f/04dc02c96a3746e3a8f1/?dl=1\n",
        "# Constitution\n",
        "# !wget https://heibox.uni-heidelberg.de/f/6d2bb00b1f324d0aaad5/?dl=1\n",
        "# Geo_Brown corpus\n",
        "# !wget https://heibox.uni-heidelberg.de/f/2c3f3084b5594ac58c9b/?dl=1\n",
        "\n",
        "# English\n",
        "# 1984\n",
        "# !wget https://heibox.uni-heidelberg.de/f/46798c5ec146485b8d96/?dl=1\n",
        "\n",
        "\n",
        "# renaming file\n",
        "!mv index.html?dl=1 go1984en-vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMA3j8b4uMkS"
      },
      "source": [
        "class clProcCorpus(object):\n",
        "    ''' we will read a text file and return a dictionary\n",
        "    this will be done on the line by line basis\n",
        "    The dictionary can be sorted later...\n",
        "    '''\n",
        "    # this is a class for processing a corpus\n",
        "\n",
        "    def __init__(self, FileIN):\n",
        "        self.DictFrq = {}\n",
        "        self.processCorpus(FileIN)\n",
        "\n",
        "    def processCorpus(self, FileIN):\n",
        "        LTerm = []\n",
        "        for Line in FileIN:\n",
        "            Line = Line.strip()\n",
        "            LLine = re.split('\\t', Line)\n",
        "            try:\n",
        "                Word = LLine[0]\n",
        "                PoS = LLine[1]\n",
        "                Lemma = LLine[2]\n",
        "            except:\n",
        "                Word = \"\"\n",
        "                PoS = \"\"\n",
        "                Lemma = \"\"\n",
        "            \n",
        "            # if re.match('N\\..*', PoS) or re.match('ADJ.*', PoS) or re.match('von', Word):\n",
        "            if re.match('N.*', PoS) or re.match('J.*', PoS):\n",
        "                LTerm.append(Word)\n",
        "            else:\n",
        "                STerm = ' '.join(LTerm)\n",
        "                LTerm = []\n",
        "\n",
        "                try:\n",
        "                    self.DictFrq[STerm] += 1\n",
        "                except:\n",
        "                    self.DictFrq[STerm] = 1        \n",
        "\n",
        "        return\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzZqoeXaAXrQ"
      },
      "source": [
        "FileIN = open('go1984en-vert.txt', 'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeEgj_dFs54B"
      },
      "source": [
        "FileOut = open('go1984en-terms.txt', 'w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSRrOa6-tTDY"
      },
      "source": [
        "# step 5: save the frequency dictionary into file, by decreasing frequencies\n",
        "# FileOutput.write( str( DictionaryFrq ) + '\\n' )\n",
        "\n",
        "OCorpus = clProcCorpus(FileIN)\n",
        "DictionaryFrq = OCorpus.DictFrq\n",
        "\n",
        "for Word, Frq in sorted( DictionaryFrq.items() , key=lambda x: x[1], reverse=True):\n",
        "    if re.search(' ', Word):\n",
        "        FileOut.write(Word + '\\t' + str(Frq) + '\\n')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsgW-9RdtjeD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}